{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37124777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "import random\n",
    "from skimage import transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, MaxPooling2D, Dropout, Conv2D, LSTM, Flatten, RandomFlip, RandomRotation, Resizing,Rescaling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "aifit_lrcn_model = load_model('aifit_lrcn.h5')\n",
    "aifit_lrcn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d010c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Setup the Pose function for images - independently for the images standalone processing.\n",
    "pose_image = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Setup the Pose function for videos - for video processing.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7,\n",
    "                          min_tracking_confidence=0.7)\n",
    "\n",
    "# Initialize mediapipe drawing class - to draw the landmarks points.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "def detectPose(image_pose, pose, draw=False, display=False):\n",
    "    image_in_RGB = cv2.cvtColor(image_pose, cv2.COLOR_BGR2RGB)\n",
    "    resultant = pose.process(image_in_RGB)\n",
    "    marked_img = cv2.cvtColor(image_pose, cv2.COLOR_BGR2GRAY)\n",
    "    marked_img = cv2.applyColorMap(marked_img, cv2.COLORMAP_HOT)\n",
    "    if resultant.pose_landmarks and draw:    \n",
    "        mp_drawing.draw_landmarks(image=marked_img, landmark_list=resultant.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),\n",
    "                                                                               thickness=1, circle_radius=1),\n",
    "                                  connection_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,0),\n",
    "                                                                               thickness=1, circle_radius=1))\n",
    "\n",
    "    if display:\n",
    "            plt.figure(figsize=[5,5])\n",
    "            plt.subplot(121);plt.imshow(image_pose[:,:,::-1]);plt.title(\"Input Image\");plt.axis('off');\n",
    "            plt.subplot(122);plt.imshow(marked_img[:,:,::-1]);plt.title(\"Pose detected Image\");plt.axis('off');\n",
    "\n",
    "    else:\n",
    "        return image_pose, marked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "SEQUENCE_LENGTH = 20\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 64, 64\n",
    "CLASSES_LIST = ['Armraise', 'Bicep Curl', 'Bird Dog', 'Fly', 'Overhead Press', 'Pushup', 'Squat']\n",
    "video_reader = cv2.VideoCapture(0)\n",
    "original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
    "\n",
    "predicted_class_name = ''\n",
    "confidence = 0\n",
    "while video_reader.isOpened():\n",
    "    ok, frame = video_reader.read() \n",
    "    \n",
    "    if not ok:\n",
    "        break\n",
    "        \n",
    "    # Resize the Frame to fixed Dimensions.\n",
    "    image_frame, marked_frame = detectPose(frame, pose_image, draw=True, display=False)\n",
    "    resized_frame = cv2.resize(marked_frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    print(np.shape(frames_queue))\n",
    "    frames_queue.append(resized_frame)\n",
    "    if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "        predicted_labels_probabilities = aifit_lrcn_model.predict(np.expand_dims(frames_queue, axis = 0))[0]\n",
    "        predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "        predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "        confidence = round(predicted_labels_probabilities[predicted_label]*100, 2)\n",
    "\n",
    "    cv2.putText(marked_frame, f'{predicted_class_name} - {confidence}%'\n",
    "                , (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('AiFit', marked_frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "video_reader.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc89313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89388afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifit",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
